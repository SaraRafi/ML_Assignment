##Plotting Data Relationships
plot(mtcars$mpg)
setwd("C://Users//Sara//Desktop//ML_Assignment")
setwd("C://Users//Sara//Desktop//ML_Assignment")
data<-read.csv(".//data")
dim(data)
names(data)
head(data)
summary(data)
str(data)
install.packages('e1071', dependencies=TRUE)
install.packages("caret", dependencies=TRUE)
set.seed(112)
inTrain1 <- createDataPartition(y=data$classe, p=0.75, list=FALSE)
training1<-data[inTrain,]
testing1<-data[-inTrain, ]
set.seed(112)
inTrain1 <- createDataPartition(y=data$classe, p=0.75, list=FALSE)
training1<-data[inTrain,]
testing1<-data[-inTrain, ]
sensorColumns = grep(pattern = "_belt|_arm|_dumbbell|_forearm", names(data))
data1<-data[,c(sensorColumns)]
names(data1)
dim(data1)
dim(data)
sensorColumns2 = grep(pattern = "_raw|_pitch|_yaw", names(data))
data2<-data[,c(sensorColumns2)]
data2
names(data2)
data1<-data[,c(data[, classe, sensorColumns)]
data1<-data[,c(data[, classe], sensorColumns)]
names(data)
data1<-data[,c(data$classe, sensorColumns)]
names(data1)
data1<-data[,(data$classe,c(sensorColumns)]
data1<-data[,(data$classe,c(sensorColumns))]
data1<-data[,c(sensorColumns,160)]
namnes(data1)
names(data1)
data2<-data[,c(sensorColumns2,160)]
unique(names(data1),names(data2))
dim(data2)
table(complete.cases(data2))
missingData = is.na(data2)
omitColumns3 = which(colSums(missingData) > 19000)
omitColumns4 = which(colSums(missingData))
data3 = data2[, -omitColumns3]
data4 = data2[, -omitColumns4]
dim(data3)
missingData
omitColumns3
omitColumns4 = which(colSums(missingData))
?which
missingData
table(missingData)
omitColumns3 = which(colSums(missingData) > 19000)
omitColumns3
omitColumns3 = which(colSums(missingData) > 1)
omitColumns3
data3 = data2[, -omitColumns3]
dim(data3)
names(data3)
summary(data2)
dim(data2)
set.seed(112)
inTrain1 <- createDataPartition(y=data3$classe, p=0.75, list=FALSE)
training1<-data3[inTrain,]
testing1<-data3[-inTrain, ]
library(caret)
set.seed(112)
inTrain1 <- createDataPartition(y=data3$classe, p=0.75, list=FALSE)
training1<-data3[inTrain,]
testing1<-data3[-inTrain, ]
inTrain1 <- createDataPartition(y=data2$classe, p=0.75, list=FALSE)
inTrain1 <- createDataPartition(y=data$classe, p=0.75, list=FALSE)
data<-read.csv(".//data")
inTrain1 <- createDataPartition(y=data$classe, p=0.75, list=FALSE)
TABLE(DATA)
table(data)
str(data)
table(data$classe)
table(data2$classe)
table(data3$classe)
table(sapply(data[1,], class))
table(sapply(data2[1,], class))
table(sapply(data3[1,], class))
inTrain1 <- createDataPartition(y=data2$classe, p=0.75, list=FALSE)
inTrain1 <- createDataPartition(y=data3$classe, p=0.75, list=FALSE)
table(complete.cases(data3))
et.seed(112)
rfit <- randomForest (classe~. , data=data3,importance=TRUE,..)
library(caret)
set.seed(112)
rfit <- randomForest (classe~. , data=data3,importance=TRUE,..)
data<-read.csv(".//data", na.strings = c("NA", "#DIV/0!"))
inTrain1 <- createDataPartition(y=data$classe, p=0.75, list=FALSE)
inTrain1 <- createDataPartition(y=data$classe, p=0.7, list=FALSE)
data<-read.table(".//data", na.strings = c("NA", "#DIV/0!"))
data<-read.table(".//data", header=TRUE,na.strings = c("NA", "#DIV/0!"))
inTrain1 <- createDataPartition(y=data$classe, p=0.7, list=FALSE)
class(data$classe)
data<-read.csv(".//data")
class(data$classe)
inTrain1 <- createDataPartition(y=data$classe, p=0.7, list=FALSE)
download.file(fileUrl, ".//data", na.strings=c("NA","#DIV/0!",""))
data<-read.csv(".//data", na.strings=c("NA","#DIV/0!",""))
inTrain1 <- createDataPartition(y=data$classe, p=0.75, list=FALSE)
sensorColumns2 = grep(pattern = "_raw|_pitch|_yaw", names(data))
data2<-data[,c(sensorColumns2,160)]
missingData = is.na(data2)
omitColumns3 = which(colSums(missingData) > 1)
data3 = data2[, -omitColumns3]
dim(data3)
omitColumns3 = which(colSums(missingData) > 19000)
data3 = data2[, -omitColumns3]
missingData = is.na(data2)
missingData
table(missingData)
colSums(missingData)
dim(data2)
n(missingData)
count(missingData)
str(data)
x<-colsums(missingData)
x<-colSums(missingData)
x
str(data$classe)
summary(data$classe)
data<-read.csv(".//data")
summary(data$classe)
dim(data)
data<-read.csv(".//data", na.strings=c("NA","#DIV/0!",""))
dim)data
data<-read.table(".//data", na.strings=c("NA","#DIV/0!",""))
data10 <- read.csv(url(fileUrl), na.strings=c("NA","#DIV/0!",""))
fileUrl<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
data10 <- read.csv(url(fileUrl), na.strings=c("NA","#DIV/0!",""))
summary(data$classe)
summary(data10$classe)
data <- read.csv(url(fileUrl), na.strings=c("NA","#DIV/0!",""))
dim(data)
sensorColumns2 = grep(pattern = "_raw|_pitch|_yaw", names(data))
data2<-data[,c(sensorColumns2,160)]
omitColumns3 = which(colSums(missingData) > 19000)
data3 = data2[, -omitColumns3]
dim(data3)
missingData = is.na(data2)
data2<-data[,c(sensorColumns2,160)]
library(caret)
inTrain1 <- createDataPartition(y=data2$classe, p=0.75, list=FALSE)
training1<-data2[inTrain,]
testing1<-data2[-inTrain, ]
inTrain <- createDataPartition(y=data2$classe, p=0.75, list=FALSE)
training1<-data2[inTrain,]
testing1<-data2[-inTrain, ]
table(sapply(data2[1,], class))
table(sapply(data[1,], class))
omitColumns3 = which(colSums(missingData) > 1)
data3 = data2[, -omitColumns3]
data3
dim(data3)
sensorColumns2 = grep(pattern = "_raw|_pitch|_yaw", names(data))
sensorColumns2
data2<-data[,c(sensorColumns2,160)]
dim(data2)
summary(data2[, 1:5])
summary(data2[, 6:10])
summary(data[, 6:10])
summary(data[, 10:15])
sensorColumns2 = grep(pattern = "raw|pitch|yaw", names(data))
data2<-data[,c(sensorColumns2,160)]
dim(data2)
omitColumns3 = which(colSums(missingData) > 1)
data3 = data2[, -omitColumns3]
dim(data3)
table(complete.cases(data3))
omitColumns3 = which(colSums(missingData) > 19000)
data3 = data2[, -omitColumns3]
dim(data3)
table(complete.cases(data3))
summary(data2)
sensorColumns2 = grep(pattern =  "_belt|_arm|_dumbbell|_forearm", names(data))
data2<-data[,c(sensorColumns2,160)]
missingData = is.na(data2)
omitColumns3 = which(colSums(missingData) > 19000)
data3 = data2[, -omitColumns3]
dim(data3)
table(complete.cases(data3))
et.seed(112)
inTrain <- createDataPartition(y=data2$classe, p=0.75, list=FALSE)
training1<-data2[inTrain,]
testing1<-data2[-inTrain, ]
table(sapply(data[1,], class))
set.seed(112)
inTrain <- createDataPartition(y=data2$classe, p=0.75, list=FALSE)
training1<-data2[inTrain,]
testing1<-data2[-inTrain, ]
table(sapply(data3[1,], class))
varcorr<-corr(training1)
varcorr<-cor(training1)
varcorr<-cor(training1)
varcorr<-cor(as.numeric(training1))
varcorr<-cor(as.numeric(training1))
dim(training1)
sensorColumns2 = grep(pattern =  "_belt|_arm|_dumbbell|_forearm", names(data))
data2<-data[,c(sensorColumns2,160)]
##Missing Values
missingData = is.na(data2)
#datachec<-data2[,!sapply(data2,any(is.na(x)))]
omitColumns3 = which(colSums(missingData) > 19000)
data3 = data2[, -omitColumns3]
dim(data3)
table(complete.cases(data3))
##Splitting Data
library(caret)
summary
set.seed(112)
inTrain <- createDataPartition(y=data3$classe, p=0.75, list=FALSE)
training1<-data3[inTrain,]
testing1<-data3[-inTrain, ]
table(sapply(data3[1,], class))
corr<-abs(cor(training1[,-53]))
diag(corr)<-0
which(corr>0.8,arr.ind=T)
x<-which(corr>0.8,arr.ind=T)
count(x)
n(x)
dim(x)
names(x)
x[,1]
colstokeep<-x[,1]
colstodelete<-x[,1]
final_train<-training[ ,- colstokeep]
final_train<-training1[ ,- colstokeep]
names(final_train)
final_train<-training1[ ,- colstodelete]
dim(final_train)
dim(training1)
53-31
final_train<-training1[ ,- colstodelete]
names(final_train)
x[,1]
x
x<-data.frame(x)
x
final_train<-training1[ ,- colstodelete]
final_data
final_train
x
x<-which(corr>0.8,arr.ind=T)
colstodelete<-x[,1]
final_train<-training1[ ,- colstodelete]
inTrain
colstodelete
names(final_train)
final_train<-training1[ , which(corr<=0.8,arr.ind=T)]
which(corr<=0.8,arr.ind=T)
y<-which(corr<=0.8,arr.ind=T)
corr<-abs(cor(training1[,-53]))
diag(corr)<-0
which(corr>0.8,arr.ind=T)
y<-which(corr<=0.8,arr.ind=T)
which(corr>0.8,arr.ind=T)
x<-which(corr>0.8,arr.ind=T)
corr<-abs(cor(training1[,-53]))
diag(corr)<-0
x<-which(corr>0.8,arr.ind=T)
set.seed(112)
inTrain <- createDataPartition(y=data3$classe, p=0.75, list=FALSE)
training1<-data3[inTrain,]
testing1<-data3[-inTrain, ]
table(sapply(data3[1,], class))
#correlation matrix
#working in training data
corr<-abs(cor(training1[,-53]))
diag(corr)<-0
x<-which(corr>0.8,arr.ind=T)
x
colstodelete<-x[,1]
x[,2]
x[,3]
corr
diag(corr)<-0
corr
x<-which(corr>0.8,arr.ind=T)
x<-which(corr>0.8)
x
final_train<-training1[ , -x]
corr
dim(corr)
dim(x)
modFit<-train(classe~. data=training1, method="rf", prox=true)
modFit<-train(classe~. ,data=training1, method="rf", prox=true)
library(randomforest)
install.packages("randomforest")
install.packages("randomForest")
library(randomforest)
install.packages("randomForest")
library(randomforest)
library(randomForest)
modFit<-train(classe~. ,data=training1, method="rf", prox=true)
library(caret)
modFit<-train(classe~. ,data=training1, method="rf", prox=true)
omitColumns3 = which(colSums(missingData) > 1)
data3 = data2[, -omitColumns3]
dim(data3)
omitColumns3 = which(colSums(missingData) >= 1)
data3 = data2[, -omitColumns3]
dim(data3)
table(complete.cases(data3))
set.seed(112)
inTrain <- createDataPartition(y=data3$classe, p=0.75, list=FALSE)
training1<-data3[inTrain,]
testing1<-data3[-inTrain, ]
table(sapply(data3[1,], class))
#correlation matrix
#working in training data
#corr<-abs(cor(training1[,-53]))
#diag(corr)<-0
#x<-which(corr>0.8,)
#final_train<-training1[ , -x]
#x<-grep("^accel",names(data) , value=TRUE)
####Splitting Data
install.packages('e1071', dependencies=TRUE)
install.packages("caret", dependencies=TRUE)
library(caret)
##########Predictors
install.packages("randomForest")
library(randomForest)
modFit<-train(classe~. ,data=training1, method="rf", prox=true)
install.packages("e1071", dependencies = TRUE)
model1<-train(classe~total_accel_belt, data=training, method="lm")
library(randomForest)
summary(data3)
set.seed(112)
inTrain <- createDataPartition(y=data3$classe, p=0.75, list=FALSE)
training1<-data3[inTrain,]
testing1<-data3[-inTrain, ]
library(caret)
set.seed(112)
inTrain <- createDataPartition(y=data3$classe, p=0.75, list=FALSE)
training1<-data3[inTrain,]
testing1<-data3[-inTrain, ]
library(randomForest)
modFit<-train(classe~. ,data=training1, method="rf", prox=true)
modfit
modFit
modFit<randomForest(classe~., data=training1)
modFit<-randomForest(classe~., data=training1)
modFit
modFit<-randomForest(classe~., data=training1)
modFit
predictionTesting = predict(modFit, newdata = testing1)
confusionMatrix(predictionTesting, testing1$classe)
setwd("C://Users//Sara//Desktop//ML_Assignment")
#Datasets
##Training data
trainUrl<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
training <- read.csv(url(trainUrl), na.strings=c("NA","#DIV/0!",""))
##Testing data
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
testing <- read.csv(url(testUrl), na.strings=c("NA","#DIV/0!",""))
#dim(data)
#names(data)
#head(data)
#summary(data)
#str(data)
####Cleaning data
##keeping variables of Interest
sensorColumns2 = grep(pattern =  "_belt|_arm|_dumbbell|_forearm", names(training))
training<-training[,c(sensorColumns2,160)]
##Missing Values
missingData = is.na(training)
omitColumns3 = which(colSums(missingData) >= 1)
training = training[, -omitColumns3]
dim(training)
table(complete.cases(training))
##Splitting Data
library(caret)
set.seed(112)
inTrain <- createDataPartition(y=data3$classe, p=0.75, list=FALSE)
subtrain<-training[inTrain,]
subtest<-training[-inTrain, ]
#table(sapply(data3[1,], class))
####correlation matrix
#corr<-abs(cor(training1[,-53]))
#diag(corr)<-0
#x<-which(corr>0.8,)
#final_train<-training1[ , -x]
#x<-grep("^accel",names(data) , value=TRUE)
##########Predictors
#install.packages("randomForest")
library(randomForest)
modFit<-randomForest(classe~., data=subtrain)
modFit
#######Testing sample
predictionTesting = predict(modFit, newdata = subtest)
confusionMatrix(predictionTesting, subtest$classe)
#######Generating Submission Files
predictionsB2 <- predict(modFit, testing, type = "classe")
setwd("C://Users//Sara//Desktop//ML_Assignment//answers")
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(predictionsB2)
library(caret)
set.seed(112)
inTrain <- createDataPartition(y=training$classe, p=0.75, list=FALSE)
subtrain<-training[inTrain,]
subtest<-training[-inTrain, ]
#table(sapply(data3[1,], class))
####correlation matrix
#corr<-abs(cor(training1[,-53]))
#diag(corr)<-0
#x<-which(corr>0.8,)
#final_train<-training1[ , -x]
#x<-grep("^accel",names(data) , value=TRUE)
##########Predictors
#install.packages("randomForest")
library(randomForest)
modFit<-randomForest(classe~., data=subtrain)
modFit
#######Testing sample
predictionTesting = predict(modFit, newdata = subtest)
confusionMatrix(predictionTesting, subtest$classe)
#######Generating Submission Files
predictionsB2 <- predict(modFit, testing, type = "classe")
setwd("C://Users//Sara//Desktop//ML_Assignment//answers")
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(predictionsB2)
predictionsB2 <- predict(modFit, testing, type = "classe")
predictionsB2 <- predict(modFit, newdata=testing)
setwd("C://Users//Sara//Desktop//ML_Assignment//answers")
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(predictionsB2)
dim(training)
modFit<-randomForest(classe~., data=subtrain)
modFit<-randomForest(classe~., data=subtrain)
#Datasets
##Training data
trainUrl<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
training <- read.csv(url(trainUrl), na.strings=c("NA","#DIV/0!",""))
##Testing data
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
testing <- read.csv(url(testUrl), na.strings=c("NA","#DIV/0!",""))
#dim(data)
#names(data)
#head(data)
#summary(data)
#str(data)
####Cleaning data
##keeping variables of Interest
sensorColumns2 = grep(pattern =  "_belt|_arm|_dumbbell|_forearm", names(training))
training<-training[,c(sensorColumns2,160)]
##Missing Values
missingData = is.na(training)
omitColumns3 = which(colSums(missingData) >= 1)
training = training[, -omitColumns3]
dim(training)
table(complete.cases(training))
##Splitting Data
library(caret)
set.seed(112)
inTrain <- createDataPartition(y=training$classe, p=0.75, list=FALSE)
subtrain<-training[inTrain,]
subtest<-training[-inTrain, ]
#table(sapply(data3[1,], class))
####correlation matrix
#corr<-abs(cor(training1[,-53]))
#diag(corr)<-0
#x<-which(corr>0.8,)
#final_train<-training1[ , -x]
#x<-grep("^accel",names(data) , value=TRUE)
##########Predictors
#install.packages("randomForest")
library(randomForest)
modFit<-randomForest(classe~., data=subtrain)
modFit
#######Testing sample
predictionTesting = predict(modFit, newdata = subtest)
confusionMatrix(predictionTesting, subtest$classe)
#######Generating Submission Files
predictionsB2 <- predict(modFit, newdata=testing)
setwd("C://Users//Sara//Desktop//ML_Assignment//answers")
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(predictionsB2)
table(traning$classe)
table(training$classe)
confusionMatrix(predictionTesting, subtest$classe)
modFit
